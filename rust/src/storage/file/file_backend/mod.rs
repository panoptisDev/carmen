// Copyright (c) 2025 Sonic Operations Ltd
//
// Use of this software is governed by the Business Source License included
// in the LICENSE file and at soniclabs.com/bsl11.
//
// Change Date: 2028-4-16
//
// On the date above, in accordance with the Business Source License, use of
// this software will be governed by the GNU Lesser General Public License v3.

use std::{fs::OpenOptions, path::Path};

#[cfg(unix)]
mod multi_page_cached_file;
mod no_seek_file;
#[cfg(unix)]
mod page_cached_file;
#[cfg(unix)]
mod page_utils;
#[cfg(unix)]
mod seek_file;

#[cfg(unix)]
pub use multi_page_cached_file::MultiPageCachedFile;
#[cfg(unix)]
pub use no_seek_file::NoSeekFile;
#[cfg(unix)]
pub use page_cached_file::PageCachedFile;
pub use seek_file::SeekFile;

use crate::error::BTResult;

/// An abstraction for concurrent file operations.
///
/// Implementations of this trait are required to ensure that concurrent operations are safe and
/// free of data races.
/// Implementations may require all read and write operations to use offsets that are multiples
/// of the chunk size and buffers whose lengths are equal to the chunk size to ensure safe
/// concurrent access. Implementations that rely on this invariant are required to check it and
/// return an error if it is violated.
#[allow(clippy::len_without_is_empty)]
#[cfg_attr(test, mockall::automock, allow(clippy::disallowed_types))]
pub trait FileBackend: Send + Sync {
    /// Opens a file at the given path with the specified options and tries to acquire a file lock.
    fn open(path: &Path, options: OpenOptions, chunk_size: usize) -> BTResult<Self, std::io::Error>
    where
        Self: Sized;

    /// Writes the entire content of `buf` starting at the given `offset`.
    fn write_all_at(&self, buf: &[u8], offset: u64) -> BTResult<(), std::io::Error>;

    /// Fills the entire `buf` with data read from the file starting at the given `offset`.
    fn read_exact_at(&self, buf: &mut [u8], offset: u64) -> BTResult<(), std::io::Error>;

    /// Flushes all changes to disk.
    fn flush(&self) -> BTResult<(), std::io::Error>;

    /// Returns the physical size of this file on disk in bytes. This size may be larger than the
    /// logical size of the file. Implementations have to ensure that reads up to the offset
    /// returned by this method succeed.
    fn len(&self) -> BTResult<u64, std::io::Error>;
}

#[cfg(test)]
mod tests {
    use std::{
        fs::{File, OpenOptions},
        io::{Read, Seek, SeekFrom, Write},
        os::unix::fs::FileExt,
    };

    use zerocopy::IntoBytes;

    use super::*;
    use crate::{
        storage::file::{MultiPageCachedFile, PageCachedFile, file_backend::page_utils::Page},
        sync::{
            Arc, Barrier,
            atomic::{AtomicU64, Ordering},
            thread,
        },
        utils::test_dir::{Permissions, TestDir},
    };

    type OpenBackendFn =
        fn(&Path, OpenOptions, usize) -> BTResult<Arc<dyn FileBackend>, std::io::Error>;

    #[rstest_reuse::template]
    #[rstest::rstest]
    #[case::seek_file(
        (|path, options, chunk_size| {
            <SeekFile as FileBackend>::open(path, options, chunk_size)
                .map(|f| Arc::new(f) as Arc<dyn FileBackend>)
        }) as OpenBackendFn
    )]
    #[case::no_seek_file(
        (|path, options, chunk_size| {
            <NoSeekFile as FileBackend>::open(path, options, chunk_size)
                .map(|f| Arc::new(f) as Arc<dyn FileBackend>)
        }) as OpenBackendFn
    )]
    #[case::page_cached_file__seek_file__direct_io(
        (|path, options, chunk_size| {
            <PageCachedFile<SeekFile, true> as FileBackend>::open(path, options, chunk_size)
                .map(|f| Arc::new(f) as Arc<dyn FileBackend>)
        }) as OpenBackendFn
    )]
    #[case::page_cached_file__no_seek_file__direct_io(
        (|path, options, chunk_size| {
            <PageCachedFile<NoSeekFile, true> as FileBackend>::open(path, options, chunk_size)
                .map(|f| Arc::new(f) as Arc<dyn FileBackend>)
        }) as OpenBackendFn
    )]
    #[case::page_cached_file__seek_file__no_direct_io(
        (|path, options, chunk_size| {
            <PageCachedFile<SeekFile, false> as FileBackend>::open(path, options, chunk_size)
                .map(|f| Arc::new(f) as Arc<dyn FileBackend>)
        }) as OpenBackendFn
    )]
    #[case::page_cached_file__no_seek_file__no_direct_io(
        (|path, options, chunk_size| {
            <PageCachedFile<NoSeekFile, false> as FileBackend>::open(path, options, chunk_size)
                .map(|f| Arc::new(f) as Arc<dyn FileBackend>)
        }) as OpenBackendFn
    )]
    #[case::multi_page_cached_file__seek_file__direct_io(
        (|path, options, chunk_size| {
            <MultiPageCachedFile<3, SeekFile, true> as FileBackend>::open(path, options, chunk_size)
                .map(|f| Arc::new(f) as Arc<dyn FileBackend>)
        }) as OpenBackendFn
    )]
    #[case::multi_page_cached_file__no_seek_file__direct_io(
        (|path, options, chunk_size| {
            <MultiPageCachedFile<3, NoSeekFile, true> as FileBackend>::open(path, options, chunk_size)
                .map(|f| Arc::new(f) as Arc<dyn FileBackend>)
        }) as OpenBackendFn
    )]
    #[case::multi_page_cached_file__seek_file__no_direct_io(
        (|path, options, chunk_size| {
            <MultiPageCachedFile<3, SeekFile, false> as FileBackend>::open(path, options, chunk_size)
                .map(|f| Arc::new(f) as Arc<dyn FileBackend>)
        }) as OpenBackendFn
    )]
    #[case::multi_page_cached_file__no_seek_file__no_direct_io(
        (|path, options, chunk_size| {
            <MultiPageCachedFile<3, NoSeekFile, false> as FileBackend>::open(path, options, chunk_size)
                .map(|f| Arc::new(f) as Arc<dyn FileBackend>)
        }) as OpenBackendFn
    )]
    fn open_backend(#[case] f: OpenBackendFn) {}

    #[rstest_reuse::apply(open_backend)]
    fn open_creates_and_opens_file(#[case] open_backend_fn: OpenBackendFn) {
        let tempdir = TestDir::try_new(Permissions::ReadWrite).unwrap();
        let path = tempdir.join("test_file.bin");

        let mut options = OpenOptions::new();
        options.create(true).read(true).write(true);

        assert!(open_backend_fn(path.as_path(), options.clone(), 1).is_ok());
        assert!(std::fs::exists(path).unwrap());
    }

    #[rstest_reuse::apply(open_backend)]
    fn open_opens_existing_file(#[case] open_backend_fn: OpenBackendFn) {
        let tempdir = TestDir::try_new(Permissions::ReadWrite).unwrap();
        let path = tempdir.join("test_file.bin");

        let mut options = OpenOptions::new();
        options.create(true).read(true).write(true);

        {
            let mut file = File::create(path.as_path()).unwrap();
            file.write_all(&[0; 10]).unwrap();
        }

        assert!(open_backend_fn(path.as_path(), options.clone(), 1).is_ok());
    }

    #[rstest_reuse::apply(open_backend)]
    fn open_fails_if_file_is_locked(#[case] open_backend_fn: OpenBackendFn) {
        let tempdir = TestDir::try_new(Permissions::ReadWrite).unwrap();
        let path = tempdir.join("test_file.bin");

        let mut options = OpenOptions::new();
        options.create(true).read(true).write(true);

        // Open the file once and lock it.
        let file = open_backend_fn(path.as_path(), options.clone(), 1);
        assert!(file.is_ok());

        // Try to open it again, while the first on is still open. This should fail.
        let file = open_backend_fn(path.as_path(), options.clone(), 1);
        assert_eq!(
            file.map(|_| ()).unwrap_err().kind(),
            std::io::ErrorKind::WouldBlock
        );
    }

    #[rstest_reuse::apply(open_backend)]
    fn open_fails_if_no_permissions(#[case] open_backend_fn: OpenBackendFn) {
        let tempdir = TestDir::try_new(Permissions::ReadWrite).unwrap();
        let path = tempdir.join("test_file.bin");

        let _ = File::create(path.as_path()).unwrap();
        tempdir.set_permissions(Permissions::ReadOnly).unwrap();

        let mut options = OpenOptions::new();
        options.read(true).write(true);

        assert_eq!(
            open_backend_fn(path.as_path(), options.clone(), 1)
                .map(|_| ())
                .unwrap_err()
                .kind(),
            std::io::ErrorKind::PermissionDenied
        );
    }

    #[rstest_reuse::apply(open_backend)]
    fn write_all_at_writes_whole_buffer_at_offset(#[case] open_backend_fn: OpenBackendFn) {
        let tempdir = TestDir::try_new(Permissions::ReadWrite).unwrap();
        let path = tempdir.join("test_file.bin");

        let mut options = OpenOptions::new();
        options.create(true).read(true).write(true);

        let data = [1; 10];
        let offset = 10;

        {
            let backend = open_backend_fn(path.as_path(), options.clone(), data.len()).unwrap();
            backend.write_all_at(&data, offset).unwrap();
            backend.flush().unwrap();
        }

        let mut file = File::open(path).unwrap();
        let mut buf = [0; 20];
        file.read_exact(&mut buf).unwrap();
        assert_eq!(buf[10..], data);
    }

    #[rstest_reuse::apply(open_backend)]
    fn write_all_at_can_write_across_pages(#[case] open_backend_fn: OpenBackendFn) {
        // This test writes data that spans 3 pages.
        // This requires the MultiPageCachedFile to have at least 3 pages in its cache.
        let tempdir = TestDir::try_new(Permissions::ReadWrite).unwrap();
        let path = tempdir.join("test_file.bin");

        let mut options = OpenOptions::new();
        options.create(true).read(true).write(true);

        let data = [1; Page::SIZE * 3];
        let offset = 0;

        {
            let backend = open_backend_fn(path.as_path(), options.clone(), data.len()).unwrap();
            backend.write_all_at(&data, offset).unwrap();
            backend.flush().unwrap();
        }

        let file = File::open(path).unwrap();
        assert_eq!(file.metadata().unwrap().len(), data.len() as u64);
        let mut buf = [0; Page::SIZE * 3];
        file.read_exact_at(&mut buf, offset).unwrap();
        assert_eq!(buf, data);
    }

    #[rstest_reuse::apply(open_backend)]
    fn write_all_at_can_write_data_to_different_pages(#[case] open_backend_fn: OpenBackendFn) {
        let tempdir = TestDir::try_new(Permissions::ReadWrite).unwrap();
        let path = tempdir.join("test_file.bin");

        let mut options = OpenOptions::new();
        options.create(true).read(true).write(true);

        let data = [1];
        let offset1 = 0;
        let offset2 = 10000;

        {
            let backend = open_backend_fn(path.as_path(), options.clone(), data.len()).unwrap();
            backend.write_all_at(&data, offset1).unwrap();
            backend.write_all_at(&data, offset2).unwrap();
            backend.flush().unwrap();
        }

        let mut file = File::open(path).unwrap();
        let mut buf = [0; 1];
        file.seek(SeekFrom::Start(offset1)).unwrap();
        file.read_exact(&mut buf).unwrap();
        assert_eq!(buf, data);
        buf = [0; 1];
        file.seek(SeekFrom::Start(offset2)).unwrap();
        file.read_exact(&mut buf).unwrap();
        assert_eq!(buf, data);
    }

    #[rstest_reuse::apply(open_backend)]
    fn read_exact_at_fills_whole_buffer_by_reading_at_offset(
        #[case] open_backend_fn: OpenBackendFn,
    ) {
        let tempdir = TestDir::try_new(Permissions::ReadWrite).unwrap();
        let path = tempdir.join("test_file.bin");

        let mut options = OpenOptions::new();
        options.create(true).read(true).write(true);

        {
            let mut file = File::create(path.as_path()).unwrap();
            let buf = [[1u8; 10], [2; 10]];
            file.write_all(buf.as_bytes()).unwrap();
        }

        let mut buf = [0; 10];
        let backend = open_backend_fn(path.as_path(), options.clone(), buf.len()).unwrap();
        backend.read_exact_at(&mut buf, 10).unwrap();
        assert_eq!(buf, [2; 10]);
    }

    #[rstest_reuse::apply(open_backend)]
    fn read_exact_at_can_read_across_pages(#[case] open_backend_fn: OpenBackendFn) {
        // This test reads data that spans 3 pages.
        // This requires the MultiPageCachedFile to have at least 3 pages in its cache.
        let tempdir = TestDir::try_new(Permissions::ReadWrite).unwrap();
        let path = tempdir.join("test_file.bin");

        let mut options = OpenOptions::new();
        options.create(true).read(true).write(true);

        let data = [1; Page::SIZE * 3];
        let offset = 0;

        {
            let mut file = File::create(path.as_path()).unwrap();
            file.write_all(&data).unwrap();
        }

        let mut buf = [0; Page::SIZE * 3];
        let backend = open_backend_fn(path.as_path(), options.clone(), buf.len()).unwrap();
        backend.read_exact_at(&mut buf, offset).unwrap();
        assert_eq!(buf, data);
    }

    #[rstest_reuse::apply(open_backend)]
    fn read_exact_at_can_read_data_from_different_pages(#[case] open_backend_fn: OpenBackendFn) {
        let tempdir = TestDir::try_new(Permissions::ReadWrite).unwrap();
        let path = tempdir.join("test_file.bin");

        let mut options = OpenOptions::new();
        options.create(true).read(true).write(true);

        let data = [1];
        let offset1 = 0;
        let offset2 = 10000;

        {
            let mut file = File::create(path.as_path()).unwrap();
            file.seek(SeekFrom::Start(offset1)).unwrap();
            file.write_all(&data).unwrap();
            file.seek(SeekFrom::Start(offset2)).unwrap();
            file.write_all(&data).unwrap();
        }

        let mut buf = [1];
        let backend = open_backend_fn(path.as_path(), options.clone(), buf.len()).unwrap();
        backend.read_exact_at(&mut buf, offset1).unwrap();
        assert_eq!(buf, data);
        backend.read_exact_at(&mut buf, offset2).unwrap();
        assert_eq!(buf, data);
    }

    #[rstest_reuse::apply(open_backend)]
    fn read_exact_at_fails_when_out_of_bounds(#[case] open_backend_fn: OpenBackendFn) {
        let tempdir = TestDir::try_new(Permissions::ReadWrite).unwrap();
        let path = tempdir.join("test_file.bin");

        let mut options = OpenOptions::new();
        options.create(true).read(true).write(true);

        {
            File::create(path.as_path()).unwrap();
        }
        // The file exists but is empty.

        let mut buf = [0; 5];
        let backend = open_backend_fn(path.as_path(), options.clone(), buf.len()).unwrap();
        let res = backend.read_exact_at(&mut buf, 5);
        assert_eq!(res.unwrap_err().kind(), std::io::ErrorKind::UnexpectedEof);
    }

    #[rstest_reuse::apply(open_backend)]
    fn access_same_page_in_parallel_does_not_deadlock(#[case] open_backend_fn: OpenBackendFn) {
        const THREADS: usize = 128;
        const PAGES: usize = 100;
        const BUF_LEN: usize = Page::SIZE / THREADS;

        let tempdir = TestDir::try_new(Permissions::ReadWrite).unwrap();
        let path = tempdir.join("test_file.bin");

        let mut options = OpenOptions::new();
        options.create(true).read(true).write(true);

        let data = vec![1; Page::SIZE * PAGES];

        {
            let mut file = File::create(path.as_path()).unwrap();
            file.write_all(&data).unwrap();
        }

        let backend = open_backend_fn(path.as_path(), options.clone(), BUF_LEN).unwrap();

        let barrier = Barrier::new(THREADS);

        thread::scope(|s| {
            for t in 0..THREADS {
                let barrier = &barrier;
                let backend = Arc::clone(&backend);
                s.spawn(move || {
                    barrier.wait(); // ensure that all threads have at least been spawned before any starts performing I/O
                    for page in 0..PAGES {
                        let mut buf = [0; BUF_LEN];
                        backend
                            .read_exact_at(&mut buf, (page * Page::SIZE + t * BUF_LEN) as u64)
                            .unwrap();
                        assert_eq!(buf, [1; BUF_LEN]);
                    }
                });
            }
        });
    }

    #[rstest_reuse::apply(open_backend)]
    fn flush_flushes_file(#[case] open_backend_fn: OpenBackendFn) {
        let tempdir = TestDir::try_new(Permissions::ReadWrite).unwrap();
        let path = tempdir.join("test_file.bin");

        let mut options = OpenOptions::new();
        options.create(true).read(true).write(true);

        let buf = [1; 10];
        let backend = open_backend_fn(path.as_path(), options.clone(), buf.len()).unwrap();
        backend.write_all_at(&buf, 0).unwrap();
        backend.flush().unwrap();

        let mut file = File::open(path.as_path()).unwrap();
        let mut buf = [0; 10];
        file.read_exact(&mut buf).unwrap();
        assert_eq!(buf, [1; 10]);
    }

    #[rstest_reuse::apply(open_backend)]
    fn len_returns_file_length(#[case] open_backend_fn: OpenBackendFn) {
        let tempdir = TestDir::try_new(Permissions::ReadWrite).unwrap();
        let path = tempdir.join("test_file.bin");

        let mut options = OpenOptions::new();
        options.create(true).read(true).write(true);

        let buf = [0; 10];
        let backend = open_backend_fn(path.as_path(), options.clone(), buf.len()).unwrap();
        backend.write_all_at(&buf, 0).unwrap();
        assert_eq!(backend.len().unwrap(), 10);
    }

    #[rstest_reuse::apply(open_backend)]
    fn read_observes_writes_of_other_threads(#[case] open_backend_fn: OpenBackendFn) {
        let tempdir = TestDir::try_new(Permissions::ReadWrite).unwrap();
        let path = tempdir.join("test_file.bin");

        let mut options = OpenOptions::new();
        options.create(true).read(true).write(true);

        let backend = open_backend_fn(path.as_path(), options.clone(), 32).unwrap();

        let iteration = AtomicU64::new(0);

        let max_iterations = 1_000;

        thread::scope(|s| {
            s.spawn(|| {
                let mut buf = [0; 32];
                loop {
                    if iteration.load(Ordering::Relaxed) > max_iterations {
                        break;
                    }

                    // wait until it is thread1's turn
                    while !iteration.load(Ordering::Relaxed).is_multiple_of(2) {}

                    let offset = iteration.load(Ordering::Relaxed) * 32;
                    if offset >= 32 {
                        // check that the previous write of thread2 is visible
                        backend.read_exact_at(&mut buf, offset - 32).unwrap();
                        assert_eq!(buf, [2; 32]);
                    }

                    // write data
                    backend.write_all_at([1; 32].as_slice(), offset).unwrap();

                    // check that thread1 observes its own write
                    backend.read_exact_at(&mut buf, offset).unwrap();
                    assert_eq!(buf, [1; 32]);

                    iteration.fetch_add(1, Ordering::Relaxed);
                }
            });
            s.spawn(|| {
                let mut buf = [0; 32];
                loop {
                    if iteration.load(Ordering::Relaxed) > max_iterations {
                        break;
                    }

                    // wait until it is thread2's turn
                    while iteration.load(Ordering::Relaxed).is_multiple_of(2) {}

                    let offset = iteration.load(Ordering::Relaxed) * 32;
                    if offset >= 32 {
                        // check that the previous write of thread1 is visible
                        backend.read_exact_at(&mut buf, offset - 32).unwrap();
                        assert_eq!(buf, [1; 32]);
                    }

                    // write data
                    backend.write_all_at([2; 32].as_slice(), offset).unwrap();

                    // check that thread2 observes its own write
                    backend.read_exact_at(&mut buf, offset).unwrap();
                    assert_eq!(buf, [2; 32]);

                    iteration.fetch_add(1, Ordering::Relaxed);
                }
            });
        });
    }
}
